{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1bf0a9",
   "metadata": {},
   "source": [
    "# Amazon SageMaker scikit-learn Bring Your Own Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6419ae0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1dded",
   "metadata": {},
   "source": [
    "_**Hosting a pre-trained scikit-learn Model in Amazon SageMaker scikit-learn Container**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon SageMaker includes functionality to support a hosted notebook environment, distributed, serverless training, and real-time hosting. We think it works best when all three of these services are used together, but they can also be used independently.  Some use cases may only require hosting.  Maybe the model was trained prior to Amazon SageMaker existing, in a different service.\n",
    "\n",
    "This notebook shows how to use a pre-trained scikit-learn model with the Amazon SageMaker scikit-learn container to quickly create a hosted endpoint for that model.\n",
    "We use the California Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html. The California Housing dataset was originally published in:\n",
    "\n",
    "> Pace, R. Kelley, and Ronald Barry. \"Sparse spatial auto-regressions.\" Statistics & Probability Letters 33.3 (1997): 291-297.\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* AWS region.\n",
    "* The IAM role arn used to give learning and hosting access to your data.\n",
    "* The S3 bucket that you want to use for training and model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fbc88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bec22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import strftime, gmtime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import mediapipe as mp\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mediapipe import solutions\n",
    "# from mediapipe.framework.formats import landmark_pb2\n",
    "# import pickle\n",
    "# import random\n",
    "# import time\n",
    "# import joblib\n",
    "\n",
    "\n",
    "\n",
    "# GET THE REGION NAME FROM THE SESSION\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# GET THE IAM ROLE DETAILS FOR EXECUTION\n",
    "role = get_execution_role()\n",
    "\n",
    "# GET THE DEFAULT BUCKET...WAS SET UP WHEN CREATING NOTEBOOK INSTANCE\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "# SET THE SUB-DIRECTORY FOR THIS INFERENCE MODEL\n",
    "prefix = \"sagemaker/ASL-Test5\"\n",
    "\n",
    "\n",
    "# IGNORE THIS FOR NOW \n",
    "# SET UP FROM (https://towardsdatascience.com/deploying-a-pre-trained-sklearn-model-on-amazon-sagemaker-826a2b5ac0b6)\n",
    "# client = boto3.client(service_name=\"sagemaker\")\n",
    "# runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "# boto_session = boto3.session.Session()\n",
    "# s3 = boto_session.resource('s3')\n",
    "# region = boto_session.region_name\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# IGNORE THIS FOR NOW \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"role: {role}\")\n",
    "print(f\"region: {region}\")\n",
    "print(f\"bucket: {bucket}\")\n",
    "print(f\"prefix: {prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e695a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade scikit-learn\n",
    "# !pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6058ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60406c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda activate conda_python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb27485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61240ddf",
   "metadata": {},
   "source": [
    "## Prepare data for model inference\n",
    "\n",
    "Load an image to be sent to the endpoint, use it later to invoke SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815007e",
   "metadata": {},
   "source": [
    "## Test the model locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\"A\":\"A\",\"B\":\"B\",\"C\":\"C\",\"D\":\"D\",\"E\":\"E\",\"F\":\"F\",\"G\":\"G\",\"H\":\"H\",\"I\":\"I\",\"K\":\"K\",\n",
    "          \"L\":\"L\",\"M\":\"M\",\"N\":\"N\",\"O\":\"O\",\"P\":\"P\",\"Q\":\"Q\",\"R\":\"R\",\"S\":\"S\",\"T\":\"T\",\"U\":\"U\",\n",
    "          \"V\":\"V\",\"W\":\"W\",\"X\":\"X\",\"Y\":\"Y\"}\n",
    "\n",
    "successCode = 0 # 0 = Success/ 1 = Failure\n",
    "\n",
    "predictedLetter = ''\n",
    "\n",
    "# LOAD THE TRAINED MODEL FROM THE PATH (**FOR JOBLIB FILES**)\n",
    "aslModelDict = joblib.load(open('./aslModel.joblib', 'rb'))\n",
    "\n",
    "# LOAD THE TRAINED MODEL FROM THE PATH (**FOR PICKLE FILES**)\n",
    "# aslModelDict = pickle.load(open(self.MODEL_PATH,'rb'))\n",
    "\n",
    "aslModel = aslModelDict['model']\n",
    "# input(\"press to continue..\")\n",
    "\n",
    "# SET THE OPTIONS FOR THE LANDMARKER INSTANCE WITH THE IMAGE MODE\n",
    "options = mp.tasks.vision.HandLandmarkerOptions(\n",
    "    base_options = mp.tasks.BaseOptions('./code/hand_landmarker.task'),\n",
    "    running_mode = mp.tasks.vision.RunningMode.IMAGE,\n",
    "    num_hands=2)\n",
    "\n",
    "# CREATE A HAND LANDMARKER INSTANCE\n",
    "detector = mp.tasks.vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# READ IN THE IMAGE FROM THE FILE PATH (THIS IS AN IMAGE OF A LETTER 'A')\n",
    "# userImage = mp.Image.create_from_file('./Local-Data/A0023_test.jpg')\n",
    "userImage = mp.Image.create_from_file('./Local-Data/4.jpg')\n",
    "\n",
    "# DETECT THE LANDMARKS\n",
    "detection_result = detector.detect(userImage)\n",
    "# print(f'detection result: {detection_result.hand_landmarks}')\n",
    "\n",
    "# IF HANDS WERE DETECTED\n",
    "if detection_result.hand_landmarks:\n",
    "    # success += 1\n",
    "    detected = []\n",
    "    # print(\"inside the detecttion result loop\\n\")\n",
    "    # FOR EACH OF THE HANDS DETECTED, ITERATE THROUGH THEM\n",
    "    # for idx in range(len(detection_result.hand_landmarks))[:1]:\n",
    "    for idx in range(len(detection_result.hand_landmarks)):\n",
    "        # FOR EACH LANDMARK, GET THE X AND Y COORDINATE\n",
    "        for i in detection_result.hand_landmarks[idx]:\n",
    "#             print('x is', i.x, 'y is', i.y, 'z is', i.z, 'visibility is', i.visibility)\n",
    "            x = i.x\n",
    "            y = i.y\n",
    "\n",
    "            # STORE X AND Y IN THE TEMP ARRAY\n",
    "            detected.append(x)\n",
    "            detected.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    # RUN THE INFERENCE MODEL AGAINST THE LANDMARKS DETECTED\n",
    "    prediction = aslModel.predict([np.asarray(detected)])\n",
    "\n",
    "    # OUTPUT THE RESULT BASED ON MATCHES IN THE LABELS DICTIONARY\n",
    "    predictedLetter = labels[(prediction[0])]\n",
    "    \n",
    "    print(f\"The predicted letter is : {predictedLetter}\")\n",
    "\n",
    "    # SET THE LOCAL VAR WITH THE RESULT FROM THE INFERENCE MODEL\n",
    "    successCode = 0\n",
    "    \n",
    "    # CREATE JSON RETURN\n",
    "    pSon = {'SuccessCode': successCode,\n",
    "           'InferResult': predictedLetter}\n",
    "    \n",
    "    jSon = json.dumps(pSon)\n",
    "    \n",
    "    print(f\"JSON result string: {jSon}\")\n",
    "\n",
    "# IF NO LANDMARKS WERE DETECTED IN THE IMAGE\n",
    "else:\n",
    "    print(f\"Inside failed inference classifier\")\n",
    "    predictedLetter = 'None'\n",
    "    successCode = 1\n",
    "          \n",
    "    # CREATE JSON RETURN\n",
    "    pSon = {'SuccessCode': successCode,\n",
    "           'InferResult': predictedLetter}\n",
    "    \n",
    "    jSon = json.dumps(pSon)\n",
    "    \n",
    "    print(f\"JSON result string: {jSon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425243b",
   "metadata": {},
   "source": [
    "### Compress the model file to a GZIP tar archive \n",
    "\n",
    "Note that the model file name must satisfy the regular expression pattern: `^[a-zA-Z0-9](-*[a-zA-Z0-9])*;`. The model file needs to be tar-zipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"model.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa131b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar cvpzf model.tar.gz $model_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc04f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IGNORE FOR HOW\n",
    "# !tar cvpzf aslModel.tar.gz $model_file_name inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea55281",
   "metadata": {},
   "source": [
    "## Upload the pre-trained model `model.tar.gz` file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ad52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e19f0",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "This involves creating a SageMaker model from the model file previously uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(f\"model data: {model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c9b40",
   "metadata": {},
   "source": [
    "### Write the Inference Script\n",
    "\n",
    "When using endpoints with the Amazon SageMaker managed `Scikit Learn` container, we need to provide an entry point script for inference that will **at least** load the saved model.\n",
    "\n",
    "After the SageMaker model server has loaded your model by calling `model_fn`, SageMaker will serve your model. Model serving is the process of responding to inference requests, received by SageMaker `InvokeEndpoint` API calls.\n",
    "\n",
    "\n",
    "We will implement also the `predict_fn()` function that takes the deserialized request object and performs inference against the loaded model.\n",
    "\n",
    "We will now create this script and call it `inference.py` and store it at the root of a directory called `code`.\n",
    "\n",
    "**Note:** You would modify the script below to implement your own inferencing logic.\n",
    "\n",
    "Additional information on model loading and model serving for scikit-learn on SageMaker can be found in the [SageMaker Scikit-learn Model Server documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#deploy-a-scikit-learn-model)\n",
    "\n",
    "There are also several functions for hosting which we won't define,\n",
    " - `input_fn()` - Takes request data and deserializes the data into an object for prediction.\n",
    " - `output_fn()` - Takes the result of prediction and serializes this according to the response content type.\n",
    "\n",
    "These will take on their default values as described [SageMaker Scikit-learn Serve a Model documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#serve-a-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad63dfa",
   "metadata": {},
   "source": [
    "### Installing additional Python dependencies\n",
    "\n",
    "It also may be necessary to supply a `requirements.txt` file to ensure any necessary dependencies are installed in the container along with the script. For this script, in addition to the Python standard libraries, we showcase how to install the `boto3` `requests`, and `nltk` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98372621",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a9337",
   "metadata": {},
   "source": [
    "Retrieve sklearn image (from https://towardsdatascience.com/deploying-a-pre-trained-sklearn-model-on-amazon-sagemaker-826a2b5ac0b6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb713345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE FOR NOW\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"0.23-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE FOR NOW\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537b8a4",
   "metadata": {},
   "source": [
    "Model Creation (from https://towardsdatascience.com/deploying-a-pre-trained-sklearn-model-on-amazon-sagemaker-826a2b5ac0b6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0570657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE FOR NOW\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_data,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_data,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93217e26",
   "metadata": {},
   "source": [
    "### Deploy with Python SDK\n",
    "\n",
    "Here we showcase the process of creating a model from s3 artifacts, that could be used to deploy a model that was trained in a different session or even out of SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE FOR NOW\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640c77a",
   "metadata": {},
   "source": [
    "#Step 3: EP Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE FOR NOW\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE FOR NOW\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "\n",
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c408083",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SKLearnModel(\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842018b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05fe2b",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, you create the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 5-10 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06fb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor = model.deploy(instance_type=\"ml.t2.medium\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45ab1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0c01a",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Now you can obtain the endpoint from the client library using the result from previous operations and generate classifications from the model using that endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407488f",
   "metadata": {},
   "source": [
    "### Invoke with the Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b263bbf",
   "metadata": {},
   "source": [
    "Let's generate the prediction for a single data point. We'll pick one from the test data generated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79227345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "predictions = predictor.predict(testX[data.feature_names])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30e6af",
   "metadata": {},
   "source": [
    "### Alternative: invoke with `boto3`\n",
    "\n",
    "This is useful when invoking the model from external clients, e.g. Lambda Functions, or other micro-services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34e183",
   "metadata": {},
   "source": [
    "#### Option 1: `csv` serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint,\n",
    "    Body=testX[data.feature_names].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ab683",
   "metadata": {},
   "source": [
    "#### Option 2: `npy` serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb751f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy serialization\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Serialise numpy ndarray as bytes\n",
    "buffer = BytesIO()\n",
    "# Assuming testX is a data frame\n",
    "np.save(buffer, testX[data.feature_names].values)\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint, Body=buffer.getvalue(), ContentType=\"application/x-npy\"\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47da86a",
   "metadata": {},
   "source": [
    "My created option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a83a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json                    \n",
    "\n",
    "import requests\n",
    "\n",
    "# api = 'http://localhost:8080/test'\n",
    "image_file = './Local-Data/4.jpg'\n",
    "\n",
    "with open(image_file, \"rb\") as f:\n",
    "    im_bytes = f.read()        \n",
    "im_b64 = base64.b64encode(im_bytes).decode(\"utf8\")\n",
    "\n",
    "# headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "  \n",
    "payload = json.dumps({\"image\": im_b64})\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint, Body=payload,ContentType=\"application/json\")\n",
    "# response = requests.post(api, data=payload, headers=headers)\n",
    "try:\n",
    "    data = response.json()     \n",
    "    print(data)                \n",
    "except requests.exceptions.RequestException:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b13de5",
   "metadata": {},
   "source": [
    "### (Optional) Delete the Endpoint\n",
    "\n",
    "If you're ready to be done with this notebook, please run the delete_endpoint line in the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5398938",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145ac7c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543c65a",
   "metadata": {},
   "source": [
    "In this notebook you successfully deployed a pre-trained scikit-learn model with the Amazon SageMaker scikit-learn container to quickly create a hosted endpoint for that model.\n",
    "You then used the Python SDK and `boto3` to invoke the endpoint with `csv` payload, and then with `npy` payload to get predictions from the model.\n",
    "\n",
    "As next steps you can try to [Automatically Scale Amazon SageMaker Models](https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling.html), [Register and Deploy Models with Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) or [Train your Model with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e9d883",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/advanced_functionality|scikit_learn_bring_your_own_model|scikit_learn_bring_your_own_model.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
